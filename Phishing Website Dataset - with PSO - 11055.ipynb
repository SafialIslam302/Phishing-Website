{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9812,
     "status": "ok",
     "timestamp": 1564858452087,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "RTxxxPVWMOCI",
    "outputId": "393559ab-bdf7-4022-cacd-963ed2cc8f03"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import f1_score,average_precision_score,recall_score,roc_auc_score\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,LabelEncoder,MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,KFold,StratifiedKFold, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('Phishing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9784,
     "status": "ok",
     "timestamp": 1564858452088,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "Z65UblxzHcTg",
    "outputId": "f7a32df4-eece-46e2-bb7e-f8098d4b9d0a"
   },
   "outputs": [],
   "source": [
    "lb_enc = LabelEncoder()\n",
    "raw_data[\"NEW_RESULT\"] = lb_enc.fit_transform(raw_data[\"Result\"])\n",
    "raw_data[[\"Result\", \"NEW_RESULT\"]]\n",
    "df = raw_data.drop(['Result'], axis = 1)\n",
    "df.head(10)\n",
    "coloum = df.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09gVn8FPHcTj"
   },
   "outputs": [],
   "source": [
    "data_X = df.drop(['NEW_RESULT'], axis=1)\n",
    "data_y = pd.DataFrame(df['NEW_RESULT'])\n",
    "y = data_y.loc[:,:].values\n",
    "X = data_X.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(y >= 1, 1, 0)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12395,
     "status": "ok",
     "timestamp": 1564858454741,
     "user": {
      "displayName": "Shanto Paul",
      "photoUrl": "https://lh5.googleusercontent.com/-S7KXSa0Wfc8/AAAAAAAAAAI/AAAAAAAAAbA/psQRjrN7I7w/s64/photo.jpg",
      "userId": "14781007155831330088"
     },
     "user_tz": 240
    },
    "id": "BLhCVo-ADcaQ",
    "outputId": "bf1af555-f70f-46d7-ecc0-91ef4ca2eed8"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pyswarms as ps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "  \n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3-IoqV8hdnA"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create an instance of the classifier\n",
    "classifier = linear_model.LogisticRegression()\n",
    "\n",
    "# Define objective function\n",
    "def f_per_particle(m, alpha):\n",
    "    \"\"\"Computes for the objective function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "    alpha: float (default is 0.5)\n",
    "        Constant weight for trading-off classifier performance\n",
    "        and number of features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed objective function\n",
    "    \"\"\"\n",
    "    total_features = coloum\n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X\n",
    "    else:\n",
    "        X_subset = X[:,m==1]\n",
    "    # Perform classification and store performance in P\n",
    "    classifier.fit(X_subset, y)\n",
    "    P = (classifier.predict(X_subset) == y).mean()\n",
    "    # Compute for the objective function\n",
    "    j = (alpha * (1.0 - P)\n",
    "        + (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W4AYbrbAnRki"
   },
   "outputs": [],
   "source": [
    "def f(x, alpha=0.88):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i], alpha) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JRd-zNHfhkyW",
    "outputId": "6c58d4d2-80dc-4d9b-fff7-0d6a95ad56e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 07:01:18,921 - pyswarms.discrete.binary - INFO - Optimize for 200 iters with {'c1': 0.6, 'c2': 0.4, 'w': 0.8, 'k': 30, 'p': 2}\n",
      "pyswarms.discrete.binary:  60%|█████████████████████████████████████▊                         |120/200, best_cost=0.453"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize swarm, arbitrary\n",
    "options = {'c1': 0.6, 'c2': 0.4, 'w':0.8, 'k': 30, 'p':2}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = coloum # dimensions should be the number of features\n",
    "optimizer = ps.discrete.BinaryPSO(n_particles=50, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TTUdGK2ntjtK"
   },
   "outputs": [],
   "source": [
    "# Create two instances of LogisticRegression\n",
    "classfier = linear_model.LogisticRegression()\n",
    "\n",
    "# Get the selected features from the final positions\n",
    "X_selected_features = X[:,pos==1]  # subset\n",
    "\n",
    "# Perform classification and store performance in P\n",
    "classifier.fit(X_selected_features, y)\n",
    "\n",
    "# Compute performance\n",
    "subset_performance = (classifier.predict(X_selected_features) == y).mean()\n",
    "\n",
    "\n",
    "print('Subset performance: %.3f' % (subset_performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(clf, X, Y):\n",
    "    print(f'Accuracy')\n",
    "    acc = cross_val_score(clf, X, Y, scoring=\"accuracy\", cv = 5)\n",
    "    print(acc)\n",
    "    print(\"Accuracy Score (Mean): \", acc.mean())\n",
    "    print(\"Standard Error: \", acc.std())\n",
    "    \n",
    "\n",
    "    print(f'\\nF1 Score')\n",
    "    f1_score = cross_val_score(clf, X, Y, scoring=\"f1\", cv = 5)\n",
    "    print(f1_score)\n",
    "    print(\"F1 Score (Mean): \", f1_score.mean())\n",
    "    print(\"Standard Error: \", f1_score.std())\n",
    "    \n",
    "    print(f'\\nPrecision')\n",
    "    pre = cross_val_score(clf, X, Y, scoring=\"precision\", cv = 5)\n",
    "    print(pre)\n",
    "    print(\"Precision (Mean): \", pre.mean())\n",
    "    print(\"Standard Error: \", pre.std())\n",
    "    \n",
    "    print(f'\\nSensitivity')\n",
    "    rec = cross_val_score(clf, X, Y, scoring=\"recall\", cv = 5)\n",
    "    print(rec)\n",
    "    print(\"Recall (Mean): \", rec.mean())\n",
    "    print(\"Standard Error: \", rec.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected_features, y, test_size=0.2, random_state=0, stratify=y)\n",
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning in Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParameterTuning_DecisionTree(features, labels):\n",
    "    params = {\n",
    "        \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "        \"min_samples_leaf\": [3, 4, 5],\n",
    "        \"min_samples_split\": [8, 10, 12],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [10, 20, 30, 40, 50],\n",
    "        \"random_state\": [10, 20, 30, 40, 50]\n",
    "    }\n",
    "    \n",
    "    rf_model = DecisionTreeClassifier()\n",
    "    \n",
    "    gsearch = GridSearchCV(estimator = rf_model, param_grid = params, cv = 5, n_jobs = -1, verbose = 1)\n",
    "    \n",
    "    gsearch.fit(features,labels)\n",
    "    \n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameterTuning_DecisionTree(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(criterion = 'entropy', max_depth = 30, max_features = 'auto',\n",
    "                                      min_samples_leaf = 4, min_samples_split = 8, random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(clf_tree, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParameterTuning_KNN(features, labels):\n",
    "    params = {\n",
    "        \"n_neighbors\": [3, 5, 8, 10, 13],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\"],\n",
    "        \"metric\": [\"minkowski\", \"euclidean\", \"manhattan\"],\n",
    "        \"p\": [1, 2, 3, 4, 5]\n",
    "    }\n",
    "    \n",
    "    rf_model = KNeighborsClassifier()\n",
    "    \n",
    "    gsearch = GridSearchCV(estimator = rf_model, param_grid = params, cv = 5, n_jobs = -1, verbose = 1)\n",
    "    \n",
    "    gsearch.fit(features,labels)\n",
    "    \n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameterTuning_KNN(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_KNN = KNeighborsClassifier(algorithm = \"kd_tree\", metric = \"minkowski\", n_neighbors = 3, p = 1, weights = \"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(clf_KNN, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParameterTuning_RF(features, labels):\n",
    "    params = {\n",
    "        \"n_estimators\": [30, 50, 70, 100],\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"max_depth\": [10, 20, 30, 40, 50],\n",
    "        \"random_state\": [10, 20, 30, 40, 50]\n",
    "    }\n",
    "    \n",
    "    rf_model = RandomForestClassifier()\n",
    "    \n",
    "    gsearch = GridSearchCV(estimator = rf_model, param_grid = params, cv = 5, n_jobs = -1, verbose = 1)\n",
    "    \n",
    "    gsearch.fit(features,labels)\n",
    "    \n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameterTuning_RF(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(criterion = 'entropy', max_depth = 20, n_estimators = 70, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(clf_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParameterTuning_SVC(features, labels):\n",
    "    params = {\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "        \"C\": [1, 3, 5],\n",
    "        \"random_state\": [10, 20, 30, 40, 50]\n",
    "    }\n",
    "    \n",
    "    rf_model = SVC()\n",
    "    \n",
    "    gsearch = GridSearchCV(estimator = rf_model, param_grid = params, cv = 5, n_jobs = -1, verbose = 1)\n",
    "    \n",
    "    gsearch.fit(features,labels)\n",
    "    \n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameterTuning_SVC(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = SVC(random_state = 10, kernel='poly', C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(clf_svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-FVD86rHcTt"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParameterTuning_MLP(features, labels):\n",
    "    params = {\n",
    "        \"hidden_layer_sizes\": [(50,50,50), (50,100,50), (100,)],\n",
    "        \"activation\": ['tanh', 'relu'],\n",
    "        \"max_iter\": [500, 600, 800, 1000],\n",
    "        \"learning_rate\": ['constant','adaptive', \"invscaling\"],\n",
    "        \"random_state\": [10, 20, 30, 40, 50]\n",
    "    }\n",
    "    \n",
    "    rf_model = MLPClassifier()\n",
    "    \n",
    "    gsearch = GridSearchCV(estimator = rf_model, param_grid = params, cv = 5, n_jobs = -1, verbose = 1)\n",
    "    \n",
    "    gsearch.fit(features,labels)\n",
    "    \n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameterTuning_MLP(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp = MLPClassifier(activation = \"relu\", hidden_layer_sizes = (50, 100, 50), learning_rate = \"constant\", \n",
    "                        max_iter = 500, random_state = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(clf_mlp, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Final_ECE_657.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
